<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>系统设计</title>
      <link href="/2025/05/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
      <url>/2025/05/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h1><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">准备写一个<span class="strong">**分布式键值存储**</span>的轮子项目，故补充一下分布式相关的知识</span><br><span class="line">先挖个坑</span><br><span class="line"><span class="strong">**https://github.com/Xten-no-brain/RaftKV**</span></span><br></pre></td></tr></table></figure><h2 id="CAP-定理"><a href="#CAP-定理" class="headerlink" title="CAP 定理"></a>CAP 定理</h2><br><br><h2 id="全局分布式ID"><a href="#全局分布式ID" class="headerlink" title="全局分布式ID"></a>全局分布式ID</h2>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络</title>
      <link href="/2025/04/27/%E7%BD%91%E7%BB%9C/"/>
      <url>/2025/04/27/%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="TCP相关"><a href="#TCP相关" class="headerlink" title="TCP相关"></a>TCP相关</h1>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统</title>
      <link href="/2025/04/27/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
      <url>/2025/04/27/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h1>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis</title>
      <link href="/2025/04/27/Redis/"/>
      <url>/2025/04/27/Redis/</url>
      
        <content type="html"><![CDATA[<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TODO</span><br><span class="line">由于项目中只用到了 Hash 结构，先对其进行详细记录，其余数据结构后续补充</span><br></pre></td></tr></table></figure><h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><ul><li>如果哈希类型元素小于 512 个，所有值小于 64 字节，以<strong>压缩列表</strong>作为数据结构</li><li>不满足上述条件则以<strong>哈希表</strong>作为数据结构</li></ul><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p><strong>key, filed, value</strong> 结构与对象的<strong>对象id，属性，值</strong>结构相似</p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ul><li>存储一个哈希表 key 的键值</li></ul><p>​HSET key field value</p><ul><li><p>获取 key 对应的 value</p><p>HGET key field</p></li><li><p>删除 key 对应的 field 键值</p><p>HDEL key field [field …]</p></li></ul><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p><strong>缓存对象</strong></p><p>例：HMSET uid:1 name X age 15，存储一个哈希表 uid:1 的键值</p><p><strong>购物车</strong></p><br><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><h3 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h3><p>int 和 SDS（简单动态字符串）</p><h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p><strong>缓存对象</strong></p><p><strong>常规计数</strong></p><p><strong>分布式锁</strong></p><p>​SET 支持 NX 参数，实现 <strong>key 不存在时才插入</strong></p><p><strong>共享 session</strong></p><br><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><h3 id="数据结构-2"><a href="#数据结构-2" class="headerlink" title="数据结构"></a>数据结构</h3><p>双向链表或压缩列表</p><h3 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h3><p>FIFO 顺序对数据进行存取操作</p><h3 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h3><p><strong>消息队列</strong></p><br><h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><h3 id="数据结构-3"><a href="#数据结构-3" class="headerlink" title="数据结构"></a>数据结构</h3><p>哈希表或整数集合</p><h3 id="特点-3"><a href="#特点-3" class="headerlink" title="特点"></a>特点</h3><p>支持取差集、并集和交集操作</p><h3 id="应用场景-3"><a href="#应用场景-3" class="headerlink" title="应用场景"></a>应用场景</h3><p><strong>点赞</strong></p><p><strong>共同关注</strong></p><br><h2 id="Zset"><a href="#Zset" class="headerlink" title="Zset"></a>Zset</h2><h3 id="数据结构-4"><a href="#数据结构-4" class="headerlink" title="数据结构"></a>数据结构</h3><p>压缩列表或跳表</p><h3 id="特点-4"><a href="#特点-4" class="headerlink" title="特点"></a>特点</h3><p>可以根据元素的权重进行排序</p><h3 id="应用场景-4"><a href="#应用场景-4" class="headerlink" title="应用场景"></a>应用场景</h3><p><strong>排行榜</strong></p><br><h2 id="Bitmap"><a href="#Bitmap" class="headerlink" title="Bitmap"></a>Bitmap</h2><h3 id="数据结构-5"><a href="#数据结构-5" class="headerlink" title="数据结构"></a>数据结构</h3><p>string作为底层结构</p><h3 id="应用场景-5"><a href="#应用场景-5" class="headerlink" title="应用场景"></a>应用场景</h3><p>适用于<strong>二值状态统计</strong>场景，海量数据下有效节省空间</p><p><strong>签到统计</strong></p><p><strong>判断用户登录态</strong></p><br><br><h1 id="持久化机制"><a href="#持久化机制" class="headerlink" title="持久化机制"></a>持久化机制</h1><h2 id="AOF日志"><a href="#AOF日志" class="headerlink" title="AOF日志"></a>AOF日志</h2><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>宕机或服务器重启后，恢复 Redis 缓存中的数据</p><p><strong>如何实现？</strong></p><p>当 Redis 写操作执行成功后，将其追加到 AOF 日志中，该文件位于磁盘中，可以实现持久化存储</p><p><strong>读操作是否需要存储？</strong></p><p>不需要，读操作不会改变数据状态，没有记录的必要</p><p><strong>为什么要在写操作执行成功后才追加？</strong></p><ol><li>保证 AOF 中记录的语法都是正确的，避免语法检查这一不必要的开销</li><li>避免当前写操作的执行被阻塞，保证 Redis 性能</li></ol><h3 id="潜在风险"><a href="#潜在风险" class="headerlink" title="潜在风险"></a>潜在风险</h3><ol><li>将 Redis 命令 追加到 AOF 这一操作，会阻塞主进程执行下一个 Redis 命令</li><li>由于写操作执行成功后才做追加，如果此时服务器挂了，还是会造成数据丢失</li></ol><h3 id="写回策略"><a href="#写回策略" class="headerlink" title="写回策略"></a>写回策略</h3><p>Redis 提供了三种写回硬盘的策略</p><ol><li>Always，每条写操作执行成功后，立即将 AOF 日志写回硬盘</li><li>Everysec，写操作执行成功后，先将其加入 AOF 缓冲区，每隔一秒将缓冲区的内容写回硬盘</li><li>No，写操作执行成功后，将其加入 AOF 缓冲区，由操作系统决定何时写回硬盘</li></ol><p><strong>这三种策略是如何实现的？</strong></p><p>本质上是 fsync() 函数的调用时机不同</p><p>Always 每次写入 AOF 数据后，立即调用 fsync() 函数</p><p>Everysec 创建一个异步任务来调用 fsync() 函数</p><p>No 永不调用 fsync() 函数</p><p><strong>如何选取？</strong></p><p>上述风险中提到的两个点，本质上是互斥的，无法同时兼顾</p><p>具体的写回策略须根据业务需要进行设置，给出参考</p><ol><li>追求高性能，采用 No 策略</li><li>追求高可靠，采用 Always 策略，尽可能减少数据丢失</li><li>追求性能且允许少量数据丢失，采取折中的 Everysec 策略</li></ol><h3 id="重写机制"><a href="#重写机制" class="headerlink" title="重写机制"></a>重写机制</h3><p>随着执行的写操作命令越来越多，AOF 文件的大小越来越大</p><p>重启 Redis 后，需要读 AOF 文件恢复缓存数据，若 AOF 文件太大，恢复过程就很慢</p><p>重写机制就是为了避免这一情况的出现</p><p><strong>如何实现？</strong></p><p>Redis 以 Key-Value 形式存储数据，对于每个 Key，只保留其最新的 Value，这样即使这个键值对被修改多次，也只会保留最新状态，并在 AOF 文件中用一条命令记录它，降低 AOF 文件大小</p><p><strong>具体过程？</strong></p><p>先创建一个新的 AOF 文件，在其中进行重写，重写成功后再覆盖旧的 AOF 文件</p><p><strong>为什么不直接覆写在旧 AOF 文件？</strong></p><p>先写到新的 AOF 中，失败的话，直接删除这个文件即可，避免因重写失败污染AOF 文件</p><p><strong>何时触发？</strong></p><ol><li><p>AOF 文件当前大小 &gt;&#x3D;  auto-aof-rewrite-min-size（ 默认64MB）</p></li><li><p>AOF 文件当前大小 &gt;&#x3D; M * (1 + auto-aof-rewrite-percentage%)，其中 M 为上次重写后 AOF 文件的大小</p><p>举例：上次重写后 AOF 文件大小为 50MB，百分比设定为100，则当前大小达到 100MB 时触发重写</p></li></ol><h3 id="后台重写"><a href="#后台重写" class="headerlink" title="后台重写"></a>后台重写</h3><p>由于此时的 AOF 文件已经很大了，且需要读取所有的键值对，此操作如果在主进程进行，就会阻碍其它命令的操作</p><p><strong>如何进行？</strong></p><p>fork 一个 bgrewriteaof 子进程在后台完成重写</p><p><strong>为什么不用更节省资源的线程？</strong></p><p>多线程之间共享内存，如果修改共享内存中的数据，就要加锁保证线程安全，造成额外开销，降低性能</p><p><strong>子进程如何访问父进程的数据？</strong></p><p>创建子进程时会复制一份父进程的页表，二者可以通过不同的虚拟内存访问相同的物理内存，节约物理内存资源。复制页表的过程会阻塞父进程，页表越大，阻塞时间越长。页表会将物理内存的权限标记为<strong>只读</strong></p><p><strong>写时复制（COW）</strong></p><p>由于物理内存权限被标记为只读，若期间子进程或父进程对该物理内存的数据进行修改，就会触发 Copy On Write 机制</p><p>具体流程为：由于违反系统权限，CPU触发<strong>写保护中断</strong>，操作系统在写保护中断处理函数中进行<strong>物理内存复制</strong>，修改子父进程的<strong>内存读写权限</strong>为可读写，最后再对内存中的数据进行写操作</p><p><strong>COW 机制的作用？</strong></p><p>发生写操作时，才复制物理内存，可以减短复制页表时对主进程的阻塞时长</p><p><strong>如果在重写过程中，主进程修改了已存在的键值对，子父进程的数据一致性如何保证？</strong></p><p>Redis内置了 AOF 重写缓冲区，其在创建 <strong>bgrewriteaof 子进程</strong>后启用。重写期间，Redis 执行完的写操作会被同步写到 <strong>AOF 缓冲区</strong>和 <strong>AOF 重写缓冲区</strong></p><p>重写期间，主进程执行三个工作：</p><ol><li>执行客户端发送到命令</li><li>将执行后的写操作追加到 AOF 缓冲区</li><li>将执行后的写操作追加到 AOF 重写缓冲区</li></ol><p>当子进程完成 AOF 重写后，会发送一个信号给主进程，主进程接收到信号后，调用信号处理函数，此函数的功能</p><ol><li>将 AOF 重写缓冲区的所有内容追加到新的 AOF 文件中，保证新旧 AOF 文件保持的数据库状态一致</li><li>将新的 AOF 文件改名，覆盖旧的 AOF 文件</li></ol><p><strong>阻塞主进程的操作</strong></p><ol><li>创建子进程时的页表复制过程</li><li>写时复制</li><li>调用信号处理函数</li></ol><br><h2 id="RDB快照"><a href="#RDB快照" class="headerlink" title="RDB快照"></a>RDB快照</h2><p>除 AOF 日志外，Redis还提供了 RDB 快照作为持久化方案</p><p><strong>二者区别</strong></p><ul><li>AOF 文件的内容为操作命令</li><li>RDB 文件的内容为二进制数据</li></ul><p>快照，顾名思义为某一个瞬间的记录。RDB 快照记录的是某一瞬间的内存数据（实际数据）；AOF 文件记录的是命令操作的日志（非实际数据）</p><p>用 RDB 文件恢复数据时，只需将其读入内存中即可；而使用用 AOF 文件时，Redis 会创建一个无网络连接的伪客户端，专门用于执行 AOF 文件中的命令。因此 RDB 恢复效率更高</p><p><strong>如何使用？</strong></p><ul><li>SAVE</li></ul><p>​在主进程中生成 RDB 文件，若写入 RDB 文件的时间过长，会阻塞主进程</p><ul><li>BGSAVE</li></ul><p>​fork 一个子进程生成 RDB 文件，避免阻塞主进程</p><p>Redis 的快照是<strong>全量快照</strong>，会将内存中的所有<strong>数据记录</strong>到磁盘中，因此执行频繁不能太高，否则 Redis   性能会降低，但频率降低，故障时丢失的数据更多（RDB的缺点）</p><p>一般设置为 <strong>5 分钟</strong>保存一次快照，这样最多丢失 5 分钟的数据</p><p><strong>BGSAVE 时能修改数据吗？</strong></p><p>可以，跟 AOF 同样会发生<strong>写时复制</strong>，但不会像 AOF 那样追加修改后的数据</p><br><h2 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h2><p>4.0 版本提出，其发生在 <strong>AOF 日志重写过程</strong></p><p>此时 fork 出来的子进程会先将与主线程共享的数据以 <strong>RDB 格式写入 AOF 文件</strong>，主线程在此阶段处理的操作命令会被记录在<strong>重写缓冲区</strong>，缓冲区的增量命令会以 <strong>AOF 格式写入 AOF 文件</strong>，写完后通知主进程将<strong>旧的 AOF 文件</strong>替换为<strong>包含 RDB 格式和 AOF 格式的 AOF 文件</strong></p><p>简而言之，若采用混合持久化，AOF <strong>前半段为 RDB 格式的全量数据</strong>，<strong>后半段为 AOF 格式的增量数据</strong></p><p><strong>有什么好处？</strong></p><p>前半段 RDB 加载速度快，后半段 AOF 记录主进程处理的操作命令，减少丢失的数据量</p><br><br><h1 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h1><h2 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h2><p>Least Recently Used，即淘汰<strong>最近最少使用</strong>的数据</p><p><strong>如何实现？</strong></p><p><strong>传统 LRU</strong></p><p>基于链表，链表中的元素按照操作顺序从前往后排列，最新操作的<strong>键</strong>会被移到头部，触发内存淘汰时，删除尾部元素即可</p><p><strong><span style="color:blue">存在问题：</span></strong></p><ul><li>需要引入链表，额外内存开销</li><li>大量数据访问时，引起很多链表移动操作，耗时太久，降低 Redis 性能</li></ul><p><strong>Redis 中是如何实现的？</strong></p><p>在 Redis 的<strong>对象结构体</strong>中加入<strong>记录最后一次访问时间的额外字段</strong></p><p>内存淘汰时，进行<strong>随机采样</strong>淘汰，随机取 5 个值（可调整），淘汰其中最久没有使用的那个</p><p><strong>缓存污染</strong></p><p>应用一次读取了大量数据，但这些数据只被读取这一次，也会将其保存在 Redis 中很长时间</p><br><h2 id="LFU"><a href="#LFU" class="headerlink" title="LFU"></a>LFU</h2><p>Least Frequently Used，即淘汰<strong>最不经常使用</strong>数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TODO</span><br><span class="line">项目用的是LRU，后续补充</span><br></pre></td></tr></table></figure><br><br><h1 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h1><h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TODO</span><br><span class="line">具体复制流程待补充</span><br></pre></td></tr></table></figure><p><strong>主节点</strong>进行读写，发生写操作时自动将其同步给从节点</p><p><strong>从节点</strong>一般只读，并执行主节点同步过来的写操作命令</p><p><strong>主从复制模式</strong></p><ul><li><p><strong><span style="color:blue">全量复制</span></strong></p><p>主从第一次同步时，采用全量复制，此时需要<strong>生成 RDB</strong> 和<strong>传输 RDB</strong>，为避免过多主节点和从节点进行 全量复制，将一部分从节点升级为<strong>经理</strong>，让其也有从节点，进而分担主节点的压力</p><p>同步完成后，主从节点会维持长连接，当主节点接收到写操作命令后，就通过长连接传播给从节点，保证主从节点的数据一致性</p></li><li><p><strong><span style="color:blue">基于长连接的命令传播</span></strong></p></li><li><p><strong><span style="color:blue">增量复制</span></strong></p><p>若主从之间网络断开又恢复正常，就只将断联期间的写操作命令同步给从节点</p></li></ul><p><strong>如何判断节点是否正常工作？</strong></p><p>心跳检测：通过 <strong>ping</strong> 操作，若一半以上的节点去 <strong>ping</strong> 同一个节点，都未收到 <strong>pong</strong> 回应，集群就认为该节点挂了，断开它的连接</p><p><strong>主从模式下，过期 key 如何处理？</strong></p><p>当主节点处理了一个 key 或淘汰算法淘汰了一个 key，主节点就模拟一条 <strong>del 命令</strong>发送个从节点，从节点收到后就执行删除 key 操作</p><p><strong>复制是同步还是异步？</strong></p><p>主节点接收到写命令后，先写到内部缓冲区，然后<strong>异步</strong>发送给从节点</p><br><h2 id="哨兵节点"><a href="#哨兵节点" class="headerlink" title="哨兵节点"></a>哨兵节点</h2><p>哨兵用于实现<strong>主从节点故障转移</strong>，其会监测主节点是否存活，如果发现主节点挂了，就选举一个从节点作新的主节点，并将新主节点的信息通知给从节点和客户端</p><p>哨兵一般以集群方式部署，至少需要 3 个哨兵节点，哨兵集群负责<strong>监控、选主、通知</strong></p><br><h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>对数据进行切片，在每个节点上存储不同的内容，实现 Redis 的<strong>分布式存储</strong>，解决<strong>在线扩容</strong>问题</p><p>即使面对亿级数据，也只需增加 Redis 实例并在集群上进行流量调度即可</p><p>整个 Redis 数据库划分为 16384 个哈希槽，集群中的节点均分这些槽位</p><h3 id="为什么设置为-16384-个槽位？"><a href="#为什么设置为-16384-个槽位？" class="headerlink" title="为什么设置为 16384 个槽位？"></a>为什么设置为 16384 个槽位？</h3><p><strong>作者原话</strong></p><p>The reason is:</p><ol><li>Normal heartbeat packets carry the full configuration of a node, that can be replaced in an idempotent way with the old in order to update an old config. This means they contain the slots configuration for a node, in raw form, that uses 2k of space with16k slots, but would use a prohibitive 8k of space using 65k slots.</li><li>At the same time it is unlikely that Redis Cluster would scale to more than 1000 mater nodes because of other design tradeoffs.</li></ol><p>So 16k was in the right range to ensure enough slots per master with a max of 1000 maters, but a small enough number to propagate the slot configuration as a raw bitmap easily. Note that in small clusters the bitmap would be hard to compress because when N is small the bitmap would have slots&#x2F;N bits set that is a large percentage of bits set.</p><p>大致意思为</p><p>1.<strong>集群模式</strong>下，需要通过<strong>心跳包机制</strong>定期广播槽位信息。这些信息以位图的形式存储和传输</p><p>16384 个槽位下，位图大小为 16384 &#x2F; 8 &#x2F; 1024 &#x3D; 2KB</p><p>65536 个槽位下，位图大小为 65536 &#x2F; 8 &#x2F; 1024 &#x3D; 8KB</p><p>心跳包大小增大了 4 倍，相应<strong>网络带宽</strong>和<strong>内存</strong>的消耗也会倍增</p><p>2.Redis 设计时预期的主节点上线为 1000 个，在此规模下，每个主节点负责约 16 个槽位，避免<strong>槽位过于稀疏</strong>的同时保证<strong>数据均衡分布</strong></p><p><strong>那为什么不设置更少一点，比如 8192 个？</strong></p><p>每个槽负责的 key 数量增加，每个节点可分配的槽位减少，槽位迁移时需要移动更多数据</p><br><br><h1 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h1><h2 id="缓存三兄弟"><a href="#缓存三兄弟" class="headerlink" title="缓存三兄弟"></a>缓存三兄弟</h2><h3 id="雪崩"><a href="#雪崩" class="headerlink" title="雪崩"></a>雪崩</h3><p>大量缓存数据在同时过期或者Redis宕机，如果此时有大量用户请求，将同时访问数据库，导致数据库压力突增，可能造成数据库宕机，进而导致系统崩溃</p><p>解决方案：</p><ul><li><p><strong>大量数据同时过期</strong></p><ul><li><p><strong><span style="color:blue">均匀设置过期时间</span></strong></p><p>设置过期时间时加上一个随机数，保证数据不会在同一时间过期</p></li><li><p><strong><span style="color:blue">互斥锁</span></strong></p><p>如果请求访问的数据不在 Redis 中，则加互斥锁，保证同一时间内只有一个请求用于构建缓存，缓存构建完成后，释放锁；未能获取互斥锁的请求，可以等待锁释放后读缓存，也可以直接返回空值或默认值</p><p>互斥锁最好设置<strong>超时时间</strong>，否则加锁的请求如果意外阻塞，就会导致锁不释放且其它请求也拿不到锁，系统出现<strong>无响应现象</strong></p><hr></li><li><p><strong><span style="color:blue">后台更新缓存</span></strong></p><p>后台线程定时更新缓存，保证缓存永久有效</p><ul><li>后台线程频繁检测缓存是否有效，若失效则读数据库更新缓存</li><li>引入 MQ 让其发送消息告知后台更新缓存</li></ul><p>上线前先把数据缓存起来，而非用户访问时才触发缓存构建，此为<strong>缓存预热</strong></p></li></ul></li><li><p><strong>Redis宕机</strong>：</p><ul><li><p><strong><span style="color:blue">服务熔断</span></strong></p><p>启动服务熔断机制，暂停业务层面对缓存的访问，直接<strong>返回错误</strong>，无需访问数据库，降低数据库压力，Redis 恢复后，再允许业务层面访问缓存</p><p>保证数据库正常运行，但业务都无法正常进行</p></li><li><p><strong><span style="color:blue">请求限流机制</span></strong></p><p>允许少量请求到达数据库，剩余请求在入口处就拒绝服务，等 Redis 恢复正常并将<strong>缓存预热</strong>后，再接除限流机制</p></li><li><p><strong><span style="color:blue">高可靠集群</span></strong></p><p>通过<strong>主从节点</strong>方式构建 Redis 集群，当主节点宕机时，从节点切换为主节点，继续提供缓存服务</p></li></ul></li></ul><br><h3 id="击穿"><a href="#击穿" class="headerlink" title="击穿"></a>击穿</h3><p>某个热点数据在缓存中过期了，此时大量请求访问这个数据，导致这些请求都击穿缓存直接访问数据库，可能使数据库过载</p><p>解决方案：</p><ul><li><p><strong>互斥锁</strong></p><p>保证同一时间只有一个业务线程更新缓存，未能获取锁的请求，要么等待锁释放后重新读取缓存，</p><p>要么返回空值或默认值</p></li><li><p><strong>不设置过期时间</strong></p><p>后台异步更新缓存；或在热点数据将过期前，通知线程更新缓存并重设过期时间</p></li></ul><br><h3 id="穿透"><a href="#穿透" class="headerlink" title="穿透"></a>穿透</h3><p>查询一个根本不存在的数据，导致每次查询都要去数据库查询，从而使得缓存形同虚设</p><p>解决方案：</p><ul><li><p>非法请求</p><p>入口处判断请求参数是否合法，若非法直接返回错误</p></li><li><p>缓存空值或默认值</p><p>针对查询的数据，在缓存中设置一个空值或默认值，后续查询就不需要查询数据库</p></li><li><p>使用布隆过滤器</p><p>数据库写入时，用布隆过滤器做标记。当请求到来时，若业务线程确认缓存失效，先通过布隆过滤器判断数据是否存在，不存在就不查数据库</p></li></ul><p><strong>布隆过滤器的工作原理</strong></p><p>核心思想：用<strong>一组位数组</strong> + <strong>多个哈希函数</strong>表示集合</p><p>工作原理：</p><ol><li><strong>初始化</strong><ul><li>创建一个长度为 m 的位数组，所有位初始化位 0</li><li>选择 k 个独立的哈希函数，分别映射输入到[0, m - 1]范围</li></ul></li><li><strong>添加元素 x</strong><ul><li>依次使用 k 个哈希函数处理元素 x，得到 k 个下标值</li><li>将这 k 个位置的 bit 设为 1</li></ul></li><li><strong>查询元素 y 是否存在</strong><ul><li>同样计算出 k 个下标值</li><li>若其中任何一个下标的 bit 为 0，则 y 一定不在集合中**（无假阴性）**</li><li>若对应位都为 1，说明 y 可能在集合中**（假阳性）**</li></ul></li></ol><p><strong>m、k 大小如何确定？</strong></p><p>与误判率有关，具体要参考相关的对数计算公式</p><p><strong>为什么会有假阳性？</strong></p><p>因为按<strong>位</strong>判断</p><p>比如说集合中存在 5，就会导致误判 3 和 1也存在集合内</p><p><strong>假阳性能否解决？</strong></p><p>本质为<strong>哈希冲突</strong>，故只能缓解</p><ol><li>加大位数组 m，牺牲一点空间降低假阳性率</li><li>使用层级布隆过滤器</li></ol><p><strong>如何记忆击穿和穿透这两个相近的词？</strong></p><p>将穿透联想成<strong>子弹穿透防弹衣</strong>，即无效防御</p><p>将击穿联想成<strong>大坝的一个缺口</strong>，导致洪水涌入</p><br><br><h2 id="数据库与缓存的一致性如何保证"><a href="#数据库与缓存的一致性如何保证" class="headerlink" title="数据库与缓存的一致性如何保证"></a>数据库与缓存的一致性如何保证</h2><p>先更新数据库，再删缓存</p><ul><li><strong><span style="color:blue">写策略步骤</span></strong><ul><li>更新数据库数据</li><li>删除缓存中的数据</li></ul></li><li><strong><span style="color:blue">读策略步骤</span></strong><ul><li>如果读取数据命中缓存，则直接返回数据</li><li>未命中，则先从数据库中读取数据，然后将其写入缓存并返回数据</li></ul></li></ul><p><strong>潜在问题</strong></p><ol><li><p><strong><span style="color:blue">短期数据不一致</span></strong></p><p>发生在数据库更新完成但缓存还未删除的这一时间窗口内</p></li><li><p><strong><span style="color:blue">长期数据不一致</span></strong></p><p>缓存删除失败（网络故障、Redis 服务异常），保留旧数据直到下次删除</p><p>解决方案：</p><ul><li>引入自动重试机制</li><li>设置 TTL 兜底</li></ul></li><li><p><strong><span style="color:blue">主从延迟放大</span></strong></p><p>读写分离下，若删除缓存后立即有查询请求，可能因主从同步延迟导致缓存回填旧数据</p><p>解决方案：</p><ul><li>关键数据强制读主节点</li><li>延迟双删，更新数据库后，延迟一定时间（如主从同步时间 + 缓冲）再次删除缓存</li></ul><p><strong>延迟双删</strong></p><p>删除缓存 -&gt; 更新数据库 -&gt; 等待主从同步 -&gt; 再次删除缓存</p></li></ol><p><strong>总结</strong></p><ul><li>对一致性要求高：<strong>延迟双删</strong> + <strong>重试机制</strong> + <strong>强制读主库</strong></li><li>对性能要求高：使用 <strong>TTL</strong> 兜底</li><li>折中：引入 <strong>MQ</strong> 异步处理</li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开发组件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL</title>
      <link href="/2025/04/27/MySQL/"/>
      <url>/2025/04/27/MySQL/</url>
      
        <content type="html"><![CDATA[<h1 id="SQL-语法"><a href="#SQL-语法" class="headerlink" title="SQL 语法"></a>SQL 语法</h1><h2 id="查询时关键字执行顺序"><a href="#查询时关键字执行顺序" class="headerlink" title="查询时关键字执行顺序"></a><strong>查询时关键字执行顺序</strong></h2><ul><li><p>FROM 找到要查的表，如果有 JOIN 则建立联表</p></li><li><p>WHERE 过滤分组前的数据</p></li><li><p>GROUP BY 进行分组</p></li><li><p>HAVING 过滤分组后的数组</p></li><li><p>SELECT 选择查询的字段</p></li><li><p>DISTINCT 去重</p></li><li><p>ORDER BY 对查询结果作排序</p></li><li><p>LIMIT &#x2F; OFFSET 限制行数</p><p>例：LIMIT 10 OFFSET 20，跳过前 20 行并往后查 10 行</p></li></ul><br><br><h2 id="慢-SQL-调优"><a href="#慢-SQL-调优" class="headerlink" title="慢 SQL 调优"></a>慢 SQL 调优</h2><h3 id="从SQL-语句出发"><a href="#从SQL-语句出发" class="headerlink" title="从SQL 语句出发"></a>从SQL 语句出发</h3><ul><li><p>避免使用 <strong>SELECT</strong> *****</p><p>读取表中所有字段，增加磁盘 I&#x2F;O 和内存消耗</p></li><li><p>使用 <strong>JOIN</strong> 而非<strong>子查询</strong></p><p>嵌套查询，时间复杂度为 O(N²)</p></li><li><p>用 <strong>IN</strong> 代替 <strong>!&#x3D;</strong> 或 <strong>&lt;&gt;</strong></p><p>!&#x3D; 或 &lt;&gt; 无法有效利用索引，特别当列允许 <strong>NULL</strong> 时，会遍历所有列</p><p>IN 的列表过长可能导致全表扫描，需结合<strong>索引</strong></p></li><li><p>避免<strong>前导通配符</strong></p><p>LIKE 利用的是 % 前的字段，使用 <strong>LIKE ‘%abc%’</strong> 无法利用索引，改为 <strong>LIKE ‘abc%’</strong></p></li></ul><br><h3 id="从索引出发"><a href="#从索引出发" class="headerlink" title="从索引出发"></a>从索引出发</h3><ul><li><p>避免<strong>过多索引</strong></p><p>每个索引都需要占用磁盘空间，增加写操作。优先为<strong>高频查询字段</strong>建索引</p></li><li><p>使用<strong>覆盖索引</strong>减少<strong>回表</strong></p><p>索引包含查询所需字段，直接从<strong>索引树</strong>返回结果</p></li></ul><br><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><ul><li><p><strong>EXPLAIN</strong> 分析执行计划</p><ul><li><span style = color:blue>连接类型 <strong>type</strong></span>：ALL 表示全表扫描，index 表示索引扫描，ref 表示索引查找</li><li><span style = color:blue>索引 <strong>key</strong></span>：实际使用的索引</li><li><span style = color:blue>行数 <strong>rows</strong></span>：预估扫描行数</li></ul></li><li><p>合并批量插入</p><p>每条 <strong>INSERT</strong> 都需要多次<strong>事务提交</strong>、<strong>日志写入</strong>、<strong>网络开销</strong></p><p>合并可减少事务开销和磁盘 I&#x2F;O</p></li><li><p>硬件优化</p><ul><li><span style = color:blue>内存</span>：扩大 <strong>Buffer Pool</strong>，减少磁盘 I&#x2F;O</li><li><span style = color:blue>磁盘</span>：使用 <strong>SSD</strong> 替换 <strong>HDD</strong>，提升随机读写速度</li><li><span style = color:blue>CPU</span>：<strong>并行</strong>查询时，多核 CPU 可加速计算</li></ul></li></ul><br><br><h2 id="笛卡尔积问题"><a href="#笛卡尔积问题" class="headerlink" title="笛卡尔积问题"></a>笛卡尔积问题</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>多表查询且无连接条件时返回的结果</p><p>假设有两个集合，A &#x3D; {a, b}, B &#x3D; {1, 2, 3}</p><p>则 A 和 B 的笛卡尔积 &#x3D; {{a, 1}, {a, 2}, {a, 3}, {b, 1}, {b, 2}, {b, 3}}，共 6 条记录</p><p><strong>MySQL 中的例子</strong></p><p>假设有表 1、表 2 两张表，数据量分别为 100 和 1000。现在对这两张表作 JOIN，若未建立查询条件，则需要从数据库中将这 1100 条数据拉取到内存中，在内存中进行100 * 1000次的计算，并对这 10W 条数据全表扫描找到想要的数据</p><br><h3 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h3><ul><li>内存占用高：如果两张表各有 10W 条数据，那么<strong>中间结果集</strong>就有 100 亿条，可能导致 <strong>OOM</strong></li><li>I&#x2F;O 频繁：可能把<strong>中间结果集</strong>写入磁盘的<strong>临时表文件</strong>，造成磁盘频繁读写</li><li>耗时长：若<strong>中间结果集</strong>很大，且无过滤条件，只能<strong>全表扫描</strong></li></ul><br><h3 id="如何避免"><a href="#如何避免" class="headerlink" title="如何避免"></a>如何避免</h3><ul><li>显式指定 JOIN，确保多表查询包含 ON 或 USING</li><li>单表查询、业务耦合</li><li>使用 EXPLAIN 排查，若输出中的 type 列未 ALL 且 rows 极大，很可能发生了笛卡尔积</li></ul><br><br><br><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><h2 id="SQL-执行流程"><a href="#SQL-执行流程" class="headerlink" title="SQL 执行流程"></a>SQL 执行流程</h2><p>MySQL分为 <strong>Server 层</strong>和<strong>存储引擎层</strong></p><h3 id="Server-层"><a href="#Server-层" class="headerlink" title="Server 层"></a>Server 层</h3><ul><li>连接器：管理客户端连接、身份认证、权限验证</li><li>查询缓存：缓存 SELECT 查询的完整结果，加速重复查询（<strong>8.0 版本移除</strong>）</li><li>解析器：进行词法分析（识别如 SELECT 的关键字）和语法分析，无误则建立语法树</li><li>预处理器：判断表和字段是否存在，将 ***** 扩展为表上的所有列</li><li>优化器：生成并选择最优执行计划（<strong>全表扫描</strong> OR <strong>索引扫描</strong>）</li><li>执行器：执行查询计划，与存储引擎交互并返回结果给客户端</li></ul><br><h3 id="存储引擎层"><a href="#存储引擎层" class="headerlink" title="存储引擎层"></a>存储引擎层</h3><ul><li>InnoDB</li><li>MyISAM</li><li>Memory</li><li>…</li></ul><p>不同存储引擎共用一个 Server 层，5.5之后，InnoDB 作为默认存储引擎。<strong>索引数据结构</strong>就是由存储引擎层实现的，不同存储引擎支持的索引类型不同</p><p><strong>存储引擎对比</strong></p><ol><li><p>事务</p><p>只有 InnoDB 支持 ACID 事务，高并发下的首选</p></li><li><p>锁机制</p><p>InnoDB 支持<strong>行级锁</strong>，粒度小，并发性能高，适合<strong>写操作频繁</strong>场景</p><p>MyISAM 和 Memory 只支持<strong>表级锁</strong></p></li><li><p>索引机制</p><p>InnoDB：<strong>聚簇索引</strong>，主键索引和数据存储在一起</p><p>MyISAM：<strong>非聚簇索引</strong>，索引和数据分开</p><p>Memory：默认为 <strong>Hash 索引</strong>，也可用 <strong>B 树</strong></p></li><li><p>数据存储位置</p><p>InnoDB 和 MyISAM 存储在磁盘中</p><p>Memory 存储在内存中，重启即丢失，适用于<strong>缓存</strong>和<strong>临时表</strong></p></li><li><p>崩溃恢复</p><p>InnoDB：undo log、redo log</p><p>MyISAM：借助 myisamchk 工具</p><p>Memory：直接丢失，无法恢复</p></li></ol><br><br><br><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="ACID-四大特性"><a href="#ACID-四大特性" class="headerlink" title="ACID 四大特性"></a>ACID 四大特性</h2><p>A：atomicity，原子性。通过 Undo log 实现</p><p>C：consistency，一致性。通过其它三个特性和应用层逻辑实现</p><p>I：isolation，隔离性。通过 MVCC 和锁实现</p><p>D：durability，持久性。通过 Redo log 实现</p><p>虽称为四大特性，但并不平级，<strong>AID</strong> 是为了达到 <strong>C</strong> 这一目标的手段</p><br><br><h2 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h2><ul><li>RU，读未提交：一个事务还未提交时，其他事务就能看到它做的变更</li><li>RC，读已提交：一个事务提交后，其他事务才能看到它做的变更</li><li>RR，可重复读：一个事务执行过程中，看到的数据都是一致的，InnoDB 默认隔离级别</li><li>Serializable，串行化：对记录加读写锁，当多个事务对同一记录做读写操作时，若发生冲突，则按顺序执行操作</li></ul><p>隔离级别：RU &lt; RC &lt; RR &lt; Serializable</p><p>并发性能：RU &gt; RC &gt; RR &gt; Serializable</p><p><strong>分别是如何实现的？</strong></p><ul><li><p>RU：</p><p>直接读取最新数据，包括其它数据未提交的修改；写操作对行加排他锁（X锁），读操作不加锁</p></li><li><p>RC：</p><p>每次查询生成一个 Read View 视图；写操作加 X 锁，事务提交后释放</p></li><li><p>RR：</p><p>事务的首次查询生成 Read View 视图，整个事务期间都使用该视图，保证一致性；写操作加行锁和临键锁（Next-Key Lock）</p></li><li><p>串行化：</p><p>读操作隐式转换为 SELECT … LOCK IN SHARE MODE，加共享锁（S锁），写操作加 X 锁</p></li></ul><p><strong>各自会造成什么问题？</strong></p><table><thead><tr><th align="center">隔离级别</th><th align="center">脏读</th><th align="center">不可重复读</th><th align="center">幻读</th><th align="center">加锁读</th></tr></thead><tbody><tr><td align="center"><strong>RU</strong></td><td align="center">✅</td><td align="center">✅</td><td align="center">✅</td><td align="center"></td></tr><tr><td align="center"><strong>RC</strong></td><td align="center"></td><td align="center">✅</td><td align="center">✅</td><td align="center"></td></tr><tr><td align="center"><strong>RR</strong></td><td align="center"></td><td align="center"></td><td align="center">✅（极少）</td><td align="center"></td></tr><tr><td align="center"><strong>串行化</strong></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">✅</td></tr></tbody></table><p>脏读：读到其他事务还未提交的数据</p><p>不可重复读：一个事务内多次查询同一字段，前后数据内容不一致</p><p>幻读：一个事务内多次查询同一字段，前后记录数量不一致</p><p>严重性：脏读 &gt; 不可重复读 &gt; 幻读</p><p><strong>可重复读如何避免幻读？</strong></p><ul><li>快照读：通过 MVCC，保证事务期间的 Read View 视图一致</li><li>当前读：SELECT … FOR UPDATE，通过临键锁阻塞其他事务在此锁范围内插入记录</li></ul><p>无法解决的幻读：</p><p>单纯的快照读或当前读都不会导致幻读现象，交叉使用时才有可能导致幻读</p><ul><li>快照读时：事务A开启后，事务B执行了插入操作，且事务A使用了 UPDATE 进行更新，后续事务A可以读到这条记录，导致幻读</li><li>当前读时：事务开启后，先执行快照读，其他事务进行插入操作，后续执行  SELECT … FOR UPDATE 或 SELECT … IN SHARE MODE，发现前后记录数量不一样，导致幻读</li></ul><p>共享锁、互斥锁兼容性</p><table><thead><tr><th align="center"></th><th align="center">X 锁</th><th align="center">S 锁</th></tr></thead><tbody><tr><td align="center">X</td><td align="center">❌</td><td align="center">❌</td></tr><tr><td align="center">S</td><td align="center">❌</td><td align="center">✅</td></tr></tbody></table><p><strong>为什么默认隔离级别为 RR，却有很多互联网公司用 RC ？</strong></p><ul><li>当前业务场景下，幻读的影响不大</li><li>提高并发性能</li></ul><p><strong>为什么不采用串行化，避免所有事务问题？</strong></p><p>串行化的并发性能过低</p><br><br><h2 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h2><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ul><li>特定隔离级别下，读写操作不会相互阻塞</li><li>读取的数据是某一时间点的一致性快照，而非最新数据</li><li>提高数据库在高并发环境下的性能和吞吐量</li></ul><br><h3 id="依赖机制"><a href="#依赖机制" class="headerlink" title="依赖机制"></a>依赖机制</h3><ul><li><p>隐藏字段</p><p>InnoDB 在每行记录中维护两个隐藏字段</p><ul><li><span style = color:blue>trx_id</span>：记录最近一次修改该行的<strong>事务 ID</strong></li><li><span style = color:blue>回滚指针 roll_pointer</span>：指向 undo log 中的旧版本，构建<strong>历史快照</strong></li></ul></li><li><p>undo log</p><p>当事务修改数据时，InnoDB 会将修改前的值记录在 undo log 中，<strong>快照读</strong>下，可以通过回滚指针查看旧版本的数据</p></li></ul><br><h3 id="快照读实现原理"><a href="#快照读实现原理" class="headerlink" title="快照读实现原理"></a>快照读实现原理</h3><p>执行快照读时创建 <strong>Read View 视图</strong></p><h4 id="Read-View-的内容"><a href="#Read-View-的内容" class="headerlink" title="Read View 的内容"></a>Read View 的内容</h4><ul><li>m_ids：创建视图时，<strong>活跃事务</strong>的事务 ID 列表，活跃事务即<strong>启动但未提交事务</strong></li><li>min_trx_id：m_ids 中的<strong>最小事务 ID</strong>，ID 比它小的一定是<strong>已提交事务</strong></li><li>max_trx_id：<strong>全局事务</strong>中最大事务 ID 值 +１</li><li>crator_trx_id：创建该视图的 事务 ID</li></ul><h4 id="MVCC-版本链"><a href="#MVCC-版本链" class="headerlink" title="MVCC 版本链"></a>MVCC 版本链</h4><p>创建视图后，可以将隐藏字段中的 trx_id 划分为三种情况</p><ul><li><strong>已提交事务</strong>：事务 ID 小于 min_trx_id，该版本记录对当前事务<strong>可见</strong></li><li><strong>启动但未提交事务</strong>：事务 ID 在 [min_trx_id, max_trx_id] 区间内，版本记录对当前事务<strong>不可见</strong></li><li><strong>还未开始的事务</strong>：事务 ID 大于 max_trx_id，版本记录对当前事务<strong>不可见</strong></li></ul><p>可通过 roll_pointer 回滚到该链上的旧版本</p><br><br><br><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h2 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h2><p>加快查询数据的速度，相当于<strong>书籍的目录</strong></p><br><br><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><h3 id="按数据结构分类"><a href="#按数据结构分类" class="headerlink" title="按数据结构分类"></a>按数据结构分类</h3><ul><li><p>B+ 树</p><p>多叉树，<strong>叶子节点</strong>存放<strong>数据</strong>，<strong>非叶子节点</strong>只存放<strong>索引</strong>，并且每个节点里的<strong>数据按主键顺序存放</strong>。父节点的索引值都会出现在下层子节点的索引值中，因此叶子节点中包含所有索引值信息。</p><p>除此之外，每个<strong>叶子节点</strong>还有两个指针，分别指向前一个和后一个叶子节点，形成<strong>双向链表</strong>，可用于实现范围查询</p><p><strong>主键索引和二级索引的 B+ 树区别</strong></p><p>主键索引的叶子节点存放<strong>实际数据</strong></p><p>二级索引的叶子节点存放<strong>主键值</strong>，再到主键索引中找到对应的数据（<strong>回表</strong>）</p><p><strong>如何避免回表？</strong></p><p>回表需要查两棵 B+ 树，效率较低。使用<strong>覆盖索引</strong>将查询需要的所有列都包含在二级索引的叶子节点，就无需到主键索引中查找行数据</p></li><li><p>全文索引 Full-Text</p><p>按<strong>关键字分词构建倒排索引</strong>，用于大文本字段的<strong>模糊查找</strong></p></li></ul><p><strong>InnoDB 为什么选 B+ 树作默认索引</strong></p><ul><li><p>对比 B 树</p><p>B 树的非叶子节点也存储数据，相较于 B+ 树，其每个节点存储的数据更多，导致单个节点更大，占用<strong>更多磁盘空间</strong>；B+ 树则把所有数据集中存储在叶子节点，非叶节点仅用于导航，节点结构更稳定，单个节点能容纳更多索引项，I&#x2F;O 效率更高</p><p>B+ 树的叶子节点通过链表相连，天然支持范围查询，而 B 树不支持。</p></li><li><p>对比二叉树</p><p>B+ 树的搜索复杂度为 O(log<sub>d</sub>N)，其中 d 表示节点允许的最大子节点个数，实际应用中 d 大于 1000，可保证在<strong>千万级数据量</strong>下，仍然可以维持 3<del>4 的层高，即一次查询只需要 3</del>4 次磁盘 I&#x2F;O 就可找到  目标数据</p><p>二叉树的子节点个数固定为 2，搜索复杂度为 O(logN)，比 B+ 树高不少，查询时需要更多的磁盘 I&#x2F;O</p></li><li><p>对比 Hash</p><p>虽然 Hash 的搜索复杂度为 O(1)，比 B+ 树快，但其只适用于<strong>等值查询</strong>而非<strong>范围查询</strong></p></li></ul><br><h3 id="按物理存储分类"><a href="#按物理存储分类" class="headerlink" title="按物理存储分类"></a>按物理存储分类</h3><ul><li><p>聚簇索引（主键索引）</p><p>叶子节点存放实际数据，完整的用户记录都存放在主键索引的 B+ 树叶子节点中</p></li><li><p>非聚簇索引（二级索引、辅助索引）</p><p>叶子节点存放主键而非实际数据</p></li></ul><br><h3 id="按字段特性分类"><a href="#按字段特性分类" class="headerlink" title="按字段特性分类"></a>按字段特性分类</h3><ul><li><p>主键索引</p><p>每表最多一个，列的值不允许有空值</p></li><li><p>唯一索引</p><p>可以多个，索引列的值必须唯一，允许空值（多个 NULL 不会触发唯一性冲突）</p></li><li><p>普通索引</p></li><li><p>前缀索引</p><p>只为字符类型字段的前几个字符建立索引，减少索引占用的存储空间，提高查询效率</p></li></ul><br><h3 id="按字段个数分类"><a href="#按字段个数分类" class="headerlink" title="按字段个数分类"></a>按字段个数分类</h3><ul><li><p>单列索引</p><p>建立在单列上，如主键索引</p></li><li><p>联合索引（复合索引）</p><p>假设存在字段 name 和 age，(name, age) 即为二者组成的联合索引</p></li></ul><p><strong>联合索引如何实现？</strong></p><p>非叶子节点用两个字段的值作为 B+ 树的 key。当联合索引在查询数据时，先按 name 字段比较，name 相同情况下再比较 age 字段，存在<strong>最左匹配原则</strong>，即按照最左优先的方式进行索引匹配，若不遵循，会导致索引失效，转为<strong>全表扫描</strong></p><p>例：联合索引 (a, b, c)，下列查询条件可以匹配联合索引</p><ul><li>where a &#x3D; 1;</li><li>where a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3;</li><li>where a &#x3D; 1 and b &#x3D; 2;</li></ul><p>由于<strong>优化器</strong>的存在，所以 a 字段在 where 子句中的<strong>顺序不重要</strong></p><p>即使写作 where b &#x3D; 2 and c &#x3D; 3 and a &#x3D; 1; 仍会被重排为 where a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3;</p><p>但如果没有 a 字段，就会失效</p><p>where a &gt; 1 and b &#x3D; 2 and c &#x3D; 3;</p><p>只能用到索引 a，因为执行 a &gt; 1 索引扫描会从 a &#x3D; 2 开始顺序扫描，此时 b 是乱序的，MySQL 并不确定 b &#x3D; 2 是否还排序在一起，触发<strong>索引截断</strong></p><p><strong>当只有最后一个字段使用范围查询时，才不会索引截断</strong></p><br><br><h2 id="什么时候需要创建索引"><a href="#什么时候需要创建索引" class="headerlink" title="什么时候需要创建索引"></a>什么时候需要创建索引</h2><ul><li><p>频繁作为 WHERE 查询条件的字段</p><p>显著减少扫描的行数</p></li><li><p>用于 ORDER BY 和 GROUP BY 的字段</p><p>按<strong>索引顺序直接输出</strong>，避免排序操作（因为 B+ 树是有序结构，按索引顺序输出即可保证有序）</p></li><li><p>用于 JOIN 条件的字段</p><p><strong>外键字段</strong>可以加速关联查询</p></li><li><p>用于覆盖索引的字段</p><p>查询可以只从索引返回，无需回表</p></li><li><p>高基数字段</p><p><strong>基数高 &#x3D; 唯一值多</strong>（用户ID、手机号），适合建索引</p><p>索引的选择性高，扫描的数据页更少</p></li></ul><br><br><h2 id="多少层的-B-树能存下-2000W-行数据"><a href="#多少层的-B-树能存下-2000W-行数据" class="headerlink" title="多少层的 B+ 树能存下 2000W 行数据"></a>多少层的 B+ 树能存下 2000W 行数据</h2><h3 id="基本参数"><a href="#基本参数" class="headerlink" title="基本参数"></a>基本参数</h3><ul><li><p>页大小：<strong>16KB &#x3D; 16 × 1024 &#x3D; 16,384 字节</strong></p></li><li><p>假设每条索引项（键+指针）占：<strong>16 字节</strong></p><ul><li>键：8 字节</li><li>指针：8 字节</li></ul></li><li><p>每个内部节点（非叶子节点）可容纳的键数：</p></li></ul><p>​16,384 &#x2F; 16 ≈ 1024 个键（→ 1025 个子节点）</p><ul><li><p>假设一条记录平均占用：<strong>128 字节</strong></p></li><li><p>每个叶子节点能容纳的记录数：16384 &#x2F; 128 &#x3D; 128 条</p></li></ul><h3 id="推导层级结构"><a href="#推导层级结构" class="headerlink" title="推导层级结构"></a>推导层级结构</h3><p><strong>第1层：叶子节点</strong></p><ul><li>总数据量：20,000,000 行</li><li>每页记录数：128</li><li>需要的叶子页数：20,000,000 &#x2F; 128 ≈ 156,250 页（即叶子节点）</li></ul><h3 id="第2层：第一层中间节点（指向叶子节点）"><a href="#第2层：第一层中间节点（指向叶子节点）" class="headerlink" title="第2层：第一层中间节点（指向叶子节点）"></a>第2层：第一层中间节点（指向叶子节点）</h3><ul><li>一个中间节点可容纳指针数 ≈ <strong>1025</strong></li><li>页数：156,250 &#x2F; 1025 ≈ 153 页</li></ul><h3 id="第3层：第二层中间节点（指向上一层）"><a href="#第3层：第二层中间节点（指向上一层）" class="headerlink" title="第3层：第二层中间节点（指向上一层）"></a>第3层：第二层中间节点（指向上一层）</h3><ul><li>153 &#x2F; 1025 ≈ <strong>0.15</strong>，只需要 1 个节点（根节点）</li></ul><p>所以<strong>总共需要 3 层</strong></p><br><br><br><h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><br><br><br><h1 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h1><br><br><br><h1 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h1>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开发组件 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
